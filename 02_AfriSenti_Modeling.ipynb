{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c02524",
   "metadata": {},
   "source": [
    "# 02 â€” AfriSenti Multilingual Modeling (XLMâ€‘R / AfriBERTa vs LSTM)\n",
    "Implements tasks 19â€“24: preprocessing, tokenization, fineâ€‘tuning, evaluation, attention viz, ablations, and crossâ€‘lingual testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4193a",
   "metadata": {},
   "source": [
    "## 0. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52470d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, roc_auc_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m label_binarize\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, re, json, random, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch, evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from datasets import Dataset as HFDataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "import emoji\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == 'notebooks') else Path.cwd()\n",
    "DATA_DIR = ROOT/'data'; FIG_DIR = ROOT/'outputs'/'figures'; TAB_DIR = ROOT/'outputs'/'tables'\n",
    "os.makedirs(FIG_DIR, exist_ok=True); os.makedirs(TAB_DIR, exist_ok=True)\n",
    "print('Device:', DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1db95",
   "metadata": {},
   "source": [
    "## 1. Load Data (local CSVs or HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b727ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(frames, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Prefer local CSVs; optionally replace with HF loader\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m load_local_csvs(\u001b[43mDATA_DIR\u001b[49m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# fallback tiny sample for structure testing only\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNimefurahi sana!\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is terrible...\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124máŠ¥á‹š á‰ áŒ£áˆ áŒ¥áˆ© áŠá‹á¢\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSio mbaya\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot good\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage only\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msw\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mam\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msw\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     31\u001b[0m     })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "def load_local_csvs(data_dir: Path):\n",
    "    csvs = list(data_dir.glob('*.csv'))\n",
    "    frames = []\n",
    "    for p in csvs:\n",
    "        try: df = pd.read_csv(p)\n",
    "        except UnicodeDecodeError: df = pd.read_csv(p, encoding='utf-8-sig')\n",
    "        except Exception: df = pd.read_csv(p, sep='\\t')\n",
    "        cols = {c.lower(): c for c in df.columns}\n",
    "        text_col = cols.get('text') or cols.get('tweet') or list(df.columns)[0]\n",
    "        label_col = cols.get('label') or cols.get('sentiment')\n",
    "        lang_col  = cols.get('lang') or cols.get('language')\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp['text'] = df[text_col].astype(str)\n",
    "        tmp['label'] = df[label_col] if label_col is not None else pd.NA\n",
    "        if lang_col: tmp['lang'] = df[lang_col].astype(str)\n",
    "        else:\n",
    "            name = p.stem.lower()\n",
    "            tmp['lang'] = 'sw' if 'sw' in name else ('am' if 'am' in name else ('en' if 'en' in name else 'unk'))\n",
    "        frames.append(tmp[['text','label','lang']])\n",
    "    return pd.concat(frames, ignore_index=True) if frames else None\n",
    "\n",
    "# Prefer local CSVs; optionally replace with HF loader\n",
    "df = load_local_csvs(DATA_DIR)\n",
    "if df is None:\n",
    "    # fallback tiny sample for structure testing only\n",
    "    df = pd.DataFrame({\n",
    "        'text':['Nimefurahi sana!','This is terrible...','áŠ¥á‹š á‰ áŒ£áˆ áŒ¥áˆ© áŠá‹á¢','Sio mbaya','Not good','Average only'],\n",
    "        'label':['positive','negative','positive','neutral','negative','neutral'],\n",
    "        'lang':['sw','en','am','sw','en','en']\n",
    "    })\n",
    "    print('Using toy sample; add CSVs in data/ for real training.')\n",
    "df = df.dropna(subset=['text']).copy()\n",
    "df['text'] = df['text'].astype(str).str.replace('\\s+',' ',regex=True).str.strip()\n",
    "df['label'] = df['label'].astype(str).str.lower()\n",
    "df['lang']  = df['lang'].astype(str).str.lower()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5300d5f4",
   "metadata": {},
   "source": [
    "## 2. Preprocessing (URLs, mentions, hashtags, emojis, slang) â€” Task 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14358141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL_RE = re.compile(r'https?://\\S+|www\\.\\S+', re.I)\n",
    "MENT_RE = re.compile(r'@\\w+')\n",
    "HASH_RE = re.compile(r'#(\\w+)')\n",
    "WS_RE   = re.compile(r'\\s+')\n",
    "\n",
    "SLANG_MAP = {\n",
    "    'en': {'u':'you','ur':'your','btw':'by the way','idk':'I do not know'},\n",
    "    'sw': {'btw':'by the way'},  # extend as needed\n",
    "    'am': {}\n",
    "}\n",
    "\n",
    "def normalize_slang(text, lang):\n",
    "    dic = SLANG_MAP.get(lang, {})\n",
    "    toks = text.split()\n",
    "    toks = [dic.get(t.lower(), t) for t in toks]\n",
    "    return ' '.join(toks)\n",
    "\n",
    "def clean_text(text, lang):\n",
    "    text = URL_RE.sub(' URL ', text)\n",
    "    text = MENT_RE.sub(' @USER ', text)\n",
    "    text = HASH_RE.sub(lambda m: f'HASHTAG_{m.group(1)}', text)\n",
    "    text = emoji.demojize(text, language='en')  # ðŸ™‚ -> :slightly_smiling_face:\n",
    "    text = normalize_slang(text, lang)\n",
    "    text = WS_RE.sub(' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = [clean_text(t,l) for t,l in zip(df['text'], df['lang'])]\n",
    "df[['lang','label','text','clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2f671",
   "metadata": {},
   "source": [
    "## 3. Split + Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid = {'negative','neutral','positive'}\n",
    "df = df[df['label'].isin(valid)].reset_index(drop=True)\n",
    "label2id = {'negative':0, 'neutral':1, 'positive':2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "df['label_id'] = df['label'].map(label2id)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=SEED, stratify=df[['lang','label']])\n",
    "train_df, val_df  = train_test_split(train_df, test_size=0.1765, random_state=SEED, stratify=train_df[['lang','label']])  # ~0.15 val\n",
    "\n",
    "print('Splits:', train_df.shape, val_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652599f",
   "metadata": {},
   "source": [
    "## 4. Tokenization (XLMâ€‘R default; switch to AfriBERTa) â€” Task 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = 'xlm-roberta-base'   # or: 'castorini/afriberta_base'\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-5\n",
    "EPOCHS = 3  # set to 5 if you want\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch['clean_text'], padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "train_tok = HFDataset.from_pandas(train_df[['clean_text','label_id','lang']]).map(tok_fn, batched=True, remove_columns=['clean_text'])\n",
    "val_tok   = HFDataset.from_pandas(val_df[['clean_text','label_id','lang']]).map(tok_fn, batched=True, remove_columns=['clean_text'])\n",
    "test_tok  = HFDataset.from_pandas(test_df[['clean_text','label_id','lang']]).map(tok_fn, batched=True, remove_columns=['clean_text'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131b56e",
   "metadata": {},
   "source": [
    "## 5. Fineâ€‘tune Transformer with Early Stopping & Gradient Clipping â€” Tasks 20â€“21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = evaluate.load('accuracy')\n",
    "f1  = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    a = acc.compute(predictions=preds, references=labels)['accuracy']\n",
    "    f = f1.compute(predictions=preds, references=labels, average='macro')['f1']\n",
    "    # ROC-AUC (one-vs-rest)\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    yb = label_binarize(labels, classes=[0,1,2])\n",
    "    try:\n",
    "        auc = roc_auc_score(yb, probs, average='macro', multi_class='ovr')\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    return {'accuracy': a, 'f1_macro': f, 'roc_auc_ovr': auc}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id\n",
    ").to(DEVICE)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ROOT/'outputs'/'transformers_runs'),\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    max_grad_norm=1.0  # gradient clipping\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print('Validation (best):', trainer.evaluate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699f951",
   "metadata": {},
   "source": [
    "## 6. Final Evaluation on Test Set â€” Task 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = trainer.predict(test_tok)\n",
    "logits = pred.predictions\n",
    "y_true = np.array(test_tok['label_id'])\n",
    "y_pred = logits.argmax(axis=-1)\n",
    "probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "acc_val = (y_pred == y_true).mean()\n",
    "f1_macro = f1.compute(predictions=y_pred, references=y_true, average='macro')['f1']\n",
    "yb = label_binarize(y_true, classes=[0,1,2])\n",
    "try:\n",
    "    auc = roc_auc_score(yb, probs, average='macro', multi_class='ovr')\n",
    "except Exception:\n",
    "    auc = float('nan')\n",
    "\n",
    "print('Test Accuracy:', acc_val, 'Macro-F1:', f1_macro, 'ROC-AUC(OVR):', auc)\n",
    "print(classification_report(y_true, y_pred, target_names=[id2label[i] for i in [0,1,2]]))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[id2label[i] for i in [0,1,2]],\n",
    "            yticklabels=[id2label[i] for i in [0,1,2]])\n",
    "plt.title('Confusion Matrix â€” Transformer')\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR/'afrisenti_confusion_transformer.png', dpi=150); plt.show()\n",
    "\n",
    "# Example predictions\n",
    "for i in np.random.choice(len(test_df), size=min(5, len(test_df)), replace=False):\n",
    "    print('â€”'*40)\n",
    "    print('Text:', test_df.iloc[i]['text'])\n",
    "    print('Clean:', test_df.iloc[i]['clean_text'])\n",
    "    print('Lang:', test_df.iloc[i]['lang'], '| Label:', test_df.iloc[i]['label'])\n",
    "    print('Pred:', id2label[int(y_pred[i])], '| Prob:', probs[i].round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611dfdb",
   "metadata": {},
   "source": [
    "## 7. Attention Visualization (single layer/head) â€” Task 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2401d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "sample_txt = test_df.iloc[0]['clean_text'] if len(test_df) > 0 else 'sample text'\n",
    "enc = tokenizer(sample_txt, return_tensors='pt', truncation=True, padding='max_length', max_length=MAX_LEN)\n",
    "enc = {k: v.to(DEVICE) for k,v in enc.items()}\n",
    "with torch.no_grad():\n",
    "    out = model(**enc, output_attentions=True)\n",
    "atts = out.attentions  # tuple: (layers) x (batch, heads, seq, seq)\n",
    "if atts:\n",
    "    att = atts[-1][0, 0].detach().cpu().numpy()  # last layer, head 0\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(att[:50,:50], aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(); plt.title('Attention heatmap (last layer, head 0)')\n",
    "    plt.tight_layout(); plt.savefig(FIG_DIR/'attention_heatmap_sample.png', dpi=150); plt.show()\n",
    "else:\n",
    "    print('Model did not return attentions.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e72e69",
   "metadata": {},
   "source": [
    "## 8. LSTM Baseline â€” Task 20 (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.texts = df['clean_text'].tolist()\n",
    "        self.labels = df['label_id'].tolist()\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tok(self.texts[idx], truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
    "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tokenizer.pad_token_id or 0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        x = self.embedding(input_ids)\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        last = self.dropout(last)\n",
    "        logits = self.fc(last)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "train_loader = DataLoader(LSTMDataset(train_df, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(LSTMDataset(val_df, tokenizer, MAX_LEN), batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(LSTMDataset(test_df, tokenizer, MAX_LEN), batch_size=BATCH_SIZE)\n",
    "\n",
    "lstm = LSTMClassifier(vocab_size=tokenizer.vocab_size).to(DEVICE)\n",
    "opt = torch.optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "best_val = float('inf'); patience = 2; wait = 0\n",
    "\n",
    "for epoch in range(5):  # up to 5 epochs\n",
    "    lstm.train(); tot=0; n=0\n",
    "    for b in train_loader:\n",
    "        ids = b['input_ids'].to(DEVICE); labels = b['labels'].to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        out = lstm(input_ids=ids, labels=labels)\n",
    "        torch.nn.utils.clip_grad_norm_(lstm.parameters(), 1.0)\n",
    "        out['loss'].backward(); opt.step()\n",
    "        tot += float(out['loss']); n += 1\n",
    "    lstm.eval(); vtot=0; vn=0\n",
    "    with torch.no_grad():\n",
    "        for b in val_loader:\n",
    "            ids = b['input_ids'].to(DEVICE); labels = b['labels'].to(DEVICE)\n",
    "            out = lstm(input_ids=ids, labels=labels); vtot += float(out['loss']); vn += 1\n",
    "    print(f'Epoch {epoch+1}: train_loss={tot/n:.4f}, val_loss={vtot/vn:.4f}')\n",
    "    if vtot/vn < best_val:\n",
    "        best_val = vtot/vn; wait = 0; torch.save(lstm.state_dict(), ROOT/'outputs'/'lstm_best.pt')\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print('Early stopping.'); break\n",
    "\n",
    "# Test LSTM\n",
    "lstm.load_state_dict(torch.load(ROOT/'outputs'/'lstm_best.pt', map_location=DEVICE)); lstm.eval()\n",
    "yt, yp, pp = [], [], []\n",
    "with torch.no_grad():\n",
    "    for b in test_loader:\n",
    "        ids = b['input_ids'].to(DEVICE); labels = b['labels'].to(DEVICE)\n",
    "        logits = lstm(input_ids=ids)['logits']\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        yt.extend(labels.cpu().numpy().tolist())\n",
    "        yp.extend(preds.cpu().numpy().tolist())\n",
    "        pp.extend(torch.softmax(logits, dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "yt = np.array(yt); yp = np.array(yp); pp = np.array(pp)\n",
    "print('LSTM Test Accuracy:', (yp==yt).mean())\n",
    "print(classification_report(yt, yp, target_names=[id2label[i] for i in [0,1,2]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b57657",
   "metadata": {},
   "source": [
    "## 9. Ablations â€” Task 23 (subset for speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd569794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def small_subset(df, n=1000):\n",
    "    if len(df) <= n: return df\n",
    "    return df.sample(n=n, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "def run_ablation(bs_list=[8,16], lr_list=[2e-5,5e-5], max_len_list=[64,128]):\n",
    "    results = []\n",
    "    base_tr = small_subset(train_df, n=1000)\n",
    "    base_va = small_subset(val_df, n=400)\n",
    "    for bs in bs_list:\n",
    "        for lr in lr_list:\n",
    "            for ml in max_len_list:\n",
    "                tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "                def tfn(b): return tok(b['clean_text'], padding='max_length', truncation=True, max_length=ml)\n",
    "                tr = HFDataset.from_pandas(base_tr[['clean_text','label_id']]).map(tfn, batched=True, remove_columns=['clean_text'])\n",
    "                va = HFDataset.from_pandas(base_va[['clean_text','label_id']]).map(tfn, batched=True, remove_columns=['clean_text'])\n",
    "                m  = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(DEVICE)\n",
    "                a  = TrainingArguments(output_dir=str(ROOT/'outputs'/'ablations'), evaluation_strategy='epoch', save_strategy='no',\n",
    "                                       per_device_train_batch_size=bs, per_device_eval_batch_size=bs,\n",
    "                                       num_train_epochs=1, learning_rate=lr, logging_steps=100, fp16=torch.cuda.is_available())\n",
    "                t  = Trainer(model=m, args=a, train_dataset=tr, eval_dataset=va, tokenizer=tok,\n",
    "                             data_collator=DataCollatorWithPadding(tok),\n",
    "                             compute_metrics=lambda p: {'f1_macro': evaluate.load('f1').compute(predictions=p.predictions.argmax(-1), references=p.label_ids, average='macro')['f1']})\n",
    "                t.train()\n",
    "                ev = t.evaluate()\n",
    "                results.append({'batch_size': bs, 'lr': lr, 'max_len': ml, 'f1_macro': ev['eval_f1_macro']})\n",
    "                print('ABL:', results[-1])\n",
    "    df_res = pd.DataFrame(results)\n",
    "    df_res.to_csv(TAB_DIR/'ablations_results.csv', index=False)\n",
    "    return df_res\n",
    "\n",
    "# To run (optional, can take time):\n",
    "# ablation_table = run_ablation()\n",
    "# ablation_table.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9040ce",
   "metadata": {},
   "source": [
    "## 10. Crossâ€‘Lingual Testing â€” Task 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_on_lang(train_lang='sw', test_lang='en', epochs=3):\n",
    "    tr = train_df[train_df['lang']==train_lang]\n",
    "    va = val_df[val_df['lang']==train_lang]\n",
    "    te = test_df[test_df['lang']==test_lang]\n",
    "    if len(tr)<10 or len(te)<10:\n",
    "        print('Not enough data for selected languages.'); return None\n",
    "\n",
    "    tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    def tf(b): return tok(b['clean_text'], padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    tr_hf = HFDataset.from_pandas(tr[['clean_text','label_id']]).map(tf, batched=True, remove_columns=['clean_text'])\n",
    "    va_hf = HFDataset.from_pandas(va[['clean_text','label_id']]).map(tf, batched=True, remove_columns=['clean_text'])\n",
    "    te_hf = HFDataset.from_pandas(te[['clean_text','label_id']]).map(tf, batched=True, remove_columns=['clean_text'])\n",
    "\n",
    "    m = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(DEVICE)\n",
    "    a = TrainingArguments(output_dir=str(ROOT/'outputs'/'crosslingual'),\n",
    "                          evaluation_strategy='epoch', save_strategy='no',\n",
    "                          num_train_epochs=epochs, learning_rate=LR,\n",
    "                          per_device_train_batch_size=BATCH_SIZE, per_device_eval_batch_size=BATCH_SIZE,\n",
    "                          fp16=torch.cuda.is_available())\n",
    "    t = Trainer(model=m, args=a, train_dataset=tr_hf, eval_dataset=va_hf, tokenizer=tok,\n",
    "                data_collator=DataCollatorWithPadding(tok), compute_metrics=compute_metrics)\n",
    "    t.train()\n",
    "    pred = t.predict(te_hf)\n",
    "    y_true = np.array(te_hf['label_id']); y_pred = pred.predictions.argmax(-1)\n",
    "    f1_macro = evaluate.load('f1').compute(predictions=y_pred, references=y_true, average='macro')['f1']\n",
    "    acc = (y_pred==y_true).mean()\n",
    "    print(f'Cross-lingual {train_lang}â†’{test_lang}: acc={acc:.4f}, f1_macro={f1_macro:.4f}')\n",
    "    return {'train_lang':train_lang,'test_lang':test_lang,'acc':acc,'f1_macro':f1_macro}\n",
    "\n",
    "# Example (uncomment when you have real data):\n",
    "# cross1 = train_on_lang('sw', 'en', epochs=3)\n",
    "# cross2 = train_on_lang('sw', 'am', epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
